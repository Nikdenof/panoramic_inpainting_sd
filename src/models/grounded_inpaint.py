import json
import logging
import os

import cv2
import numpy as np
import torch
from PIL import Image
from diffusers import StableDiffusionInpaintPipeline
from tqdm import tqdm

from GSAM.GroundingDINO.groundingdino.util.inference import load_image
from src.features.opencv_transforms import mask_pil_preprocess
from src.models.predict_dino import detect, get_dino_model
from src.models.predict_sam import get_sam_model, segment
from src.utils.constants import SD_SEED, DINO2SD_DICT, DILATE_RADIUS, DILATE_ITERATION


CLASSES2DETECT = ["sky", "grass"]


def cv2_display(image_og):
    return cv2.cvtColor(np.array(image_og), cv2.COLOR_BGR2RGB)


def save_dict_to_json(data, filepath):
    with open(filepath, "w") as json_file:
        json.dump(data, json_file)


def draw_mask(mask, image, random_color=True):
    if random_color:
        color = np.concatenate([np.random.random(3), np.array([0.8])], axis=0)
    else:
        color = np.array([30 / 255, 144 / 255, 255 / 255, 0.6])
    h, w = mask.shape[-2:]
    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)

    annotated_frame_pil = Image.fromarray(image).convert("RGBA")
    mask_image_pil = Image.fromarray(
        (mask_image.cpu().numpy() * 255).astype(np.uint8)
    ).convert("RGBA")

    return np.array(Image.alpha_composite(annotated_frame_pil, mask_image_pil))


def generate_image(
    in_image,
    in_mask,
    prompt,
    negative_prompt,
    pipe,
    seed,
    device,
    resize_hw=512,
    strength_param=0.8,
    guidance_param=10,
):
    # resize for inpainting
    w, h = in_image.size
    if resize_hw is not None:
        in_image = in_image.resize((resize_hw, resize_hw))
        in_mask = in_mask.resize((resize_hw, resize_hw))

    generator = torch.Generator(device).manual_seed(seed)

    result = pipe(
        image=in_image,
        mask_image=in_mask,
        prompt=prompt,
        negative_prompt=negative_prompt,
        generator=generator,
        strength=strength_param,  # 1 is default
        guidance_scale=guidance_param,  # 7.5 is default
        padding_mask_crop=16,
    )
    result = result.images[0]

    return result.resize((w, h))


def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    groundingdino_model = get_dino_model(device)
    sam_predictor = get_sam_model(device)
    sd_pipe = StableDiffusionInpaintPipeline.from_pretrained(
        "stabilityai/stable-diffusion-2-inpainting",
        torch_dtype=torch.float16,
    ).to(device)
    # disable the progress bar
    sd_pipe.set_progress_bar_config(disable=True)

    # image_directory = "../../data/raw/vadim_data_v0/"
    image_directory = "../../data/raw/vadim_data_v1/Archive/"
    out_directory = "../../data/processed/sky_sd_test_dr3_di5_v1/"
    os.makedirs(out_directory, exist_ok=True)
    save_dict_to_json(DINO2SD_DICT, os.path.join(out_directory, "params.json"))

    for img_name in tqdm(os.listdir(image_directory), desc="Processing images"):
        local_image_path = os.path.join(image_directory, img_name)
        # local_image_path = "../../data/raw/vadim_data_v0/1685684068_klau-club-p-dom-s-gazonom-2.jpeg"
        output_image_path = os.path.join(out_directory, img_name)

        image_source, image = load_image(local_image_path)

        out_image = inpaint_image(
            image_source,
            image,
            groundingdino_model,
            sam_predictor,
            sd_pipe,
            device,
            DINO2SD_DICT,
        )
        out_image_np = np.array(out_image, dtype=np.uint8)
        stacked_image = cv2.vconcat([image_source, out_image_np])
        img_rgb = cv2.cvtColor(stacked_image, cv2.COLOR_BGR2RGB)
        cv2.imwrite(output_image_path, img_rgb)

    logging.info("End of main function")


def inpaint_image(
    image_source,
    image,
    groundingdino_model,
    sam_predictor,
    sd_pipe,
    device,
    prompt_dict,
):
    dino_prompt_in = f"{'. '.join(CLASSES2DETECT)}."
    annotated_frame, detected_boxes, detected_classes = detect(
        image, image_source, text_prompt=dino_prompt_in, model=groundingdino_model
    )

    # Step 2. Segmenting using SAM based on bbox generated by DINO
    segmented_frame_masks = segment(
        image_source, sam_predictor, boxes=detected_boxes, device=device
    )
    annotated_frame_with_mask = draw_mask(segmented_frame_masks[0][0], annotated_frame)

    # Step 3. Inpainting process
    image_pil = Image.fromarray(image_source)
    for mask_tensor, class_detected in zip(segmented_frame_masks, detected_classes):
        mask_og = mask_tensor[0].cpu().numpy()

        image_mask_pil = Image.fromarray(mask_og)
        image_mask_pil = mask_pil_preprocess(
            image_mask_pil,
            dilate_radius=DILATE_RADIUS,
            dilate_iterations=DILATE_ITERATION,
        )

        prompt_list = prompt_dict.get(class_detected)
        if prompt_list is None:
            continue

        if class_detected in ["sky"]:
            fill_color = prompt_list[2]
            img_interim = np.array(image_pil)
            # Filling by initial mask
            img_interim[mask_og] = fill_color
            image_pil = Image.fromarray(img_interim)
        elif class_detected in ["grass"]:
            img_interim = np.array(image_pil)
            img_colored = img_interim.copy()
            # img_colored[mask_og] = [0, 255, 0]
            img_colored[mask_og] = [63, 155, 11]
            img_out = cv2.addWeighted(
                img_colored, 0.3, img_interim, 0.7, 0, img_colored
            )
            image_pil = Image.fromarray(img_out)

        strength_class = prompt_list[3]
        guidance_class = prompt_list[4]

        image_pil = generate_image(
            in_image=image_pil,
            in_mask=image_mask_pil,
            prompt=prompt_list[0],
            negative_prompt=prompt_list[1],
            pipe=sd_pipe,
            seed=SD_SEED,
            device=device,
            strength_param=strength_class,
            guidance_param=guidance_class,
        )
        logging.info(f"Iteration {class_detected} finished")

    return image_pil


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
    )
    main()
